{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fastai\n",
    "!pip install nbdev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from fastai.vision.all import *\n",
    "\n",
    "path = Path(\"path_to_your_dataset\")\n",
    "\n",
    "# Create a DataLoader for training\n",
    "dls = ImageDataLoaders.from_folder(path, train='train', valid='valid', \n",
    "                                   item_tfms=Resize(224), batch_tfms=aug_transforms(), \n",
    "                                   bs=64)\n",
    "\n",
    "\n",
    "\n",
    "# Define the model using FastAI's `cnn_learner` function\n",
    "# ResNet is a commonly used architecture. You can replace resnet34 with any other architecture\n",
    "learner = cnn_learner(dls, resnet34, metrics=accuracy)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "learner.fine_tune(10)  # Train for 10 epochs \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "from fastai.vision.widgets import *\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "path = Path(\"path_to_your_dataset\")\n",
    "\n",
    "im = Image.open(path)\n",
    "im.to_thumb(128,128)\n",
    "\n",
    "filenames = get_image_files(path)\n",
    "filenames\n",
    "\n",
    "#virify images\n",
    "failed = verify_images(filenames)\n",
    "failed\n",
    "\n",
    "street = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y= #get the joystick inputs(imagename) or use parent_label to get the folder name,\n",
    "    item_tfms=Resize(128))\n",
    "\n",
    "dls = street.dataloaders(path)\n",
    "\n",
    "dls.train.show_batch(max_n=4, nrows=1)\n",
    "dls.valid.show_batch(max_n=4, nrows=1)\n",
    "\n",
    "our_out_of_the_box_model = vision_learner(dls, resnet50, metrics=error_rate)\n",
    "our_out_of_the_box_model.fine_tune(3)\n",
    "\n",
    "\n",
    "interp = ClassificationInterpretation.from_learner(our_out_of_the_box_model)\n",
    "interp.plot_confusion_matrix()\n",
    "\n",
    "interp.plot_top_losses(5, nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a custom CNN\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, stride=3)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=3)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(128*output_dim_x*output_dim_y, 5)  # Adjust output dim after flatten\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Create data loaders\n",
    "dls = ImageDataLoaders.from_folder(path, item_tfms=Resize(224), batch_tfms=aug_transforms(), bs=64)\n",
    "\n",
    "# Wrap your model into a Learner\n",
    "learner = Learner(dls, MyModel(), metrics=accuracy)\n",
    "\n",
    "# Train the custom model\n",
    "learner.fit_one_cycle(10) "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
