{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (8.3.18)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from ultralytics) (2.1.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from ultralytics) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from ultralytics) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from ultralytics) (2.5.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from ultralytics) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from ultralytics) (6.1.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from ultralytics) (2.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gebruiker\\onedrive - thomas more\\bureaublad\\cvc_challenge\\cvc_challenge_env\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ultralytics YOLO üöÄ, AGPL-3.0 license\n",
      "# COCO128 dataset https://www.kaggle.com/datasets/ultralytics/coco128 (first 128 images from COCO train2017) by Ultralytics\n",
      "# Documentation: https://docs.ultralytics.com/datasets/detect/coco/\n",
      "# Example usage: yolo train data=coco128.yaml\n",
      "# parent\n",
      "# ‚îú‚îÄ‚îÄ ultralytics\n",
      "# ‚îî‚îÄ‚îÄ datasets\n",
      "#     ‚îî‚îÄ‚îÄ coco128  ‚Üê downloads here (7 MB)\n",
      "\n",
      "# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
      "path: ../datasets/coco128 # dataset root dir\n",
      "train: images/train2017 # train images (relative to 'path') 128 images\n",
      "val: images/train2017 # val images (relative to 'path') 128 images\n",
      "test: # test images (optional)\n",
      "\n",
      "# Classes\n",
      "names:\n",
      "  0: person\n",
      "  1: bicycle\n",
      "  2: car\n",
      "  3: motorcycle\n",
      "  4: airplane\n",
      "  5: bus\n",
      "  6: train\n",
      "  7: truck\n",
      "  8: boat\n",
      "  9: traffic light\n",
      "  10: fire hydrant\n",
      "  11: stop sign\n",
      "  12: parking meter\n",
      "  13: bench\n",
      "  14: bird\n",
      "  15: cat\n",
      "  16: dog\n",
      "  17: horse\n",
      "  18: sheep\n",
      "  19: cow\n",
      "  20: elephant\n",
      "  21: bear\n",
      "  22: zebra\n",
      "  23: giraffe\n",
      "  24: backpack\n",
      "  25: umbrella\n",
      "  26: handbag\n",
      "  27: tie\n",
      "  28: suitcase\n",
      "  29: frisbee\n",
      "  30: skis\n",
      "  31: snowboard\n",
      "  32: sports ball\n",
      "  33: kite\n",
      "  34: baseball bat\n",
      "  35: baseball glove\n",
      "  36: skateboard\n",
      "  37: surfboard\n",
      "  38: tennis racket\n",
      "  39: bottle\n",
      "  40: wine glass\n",
      "  41: cup\n",
      "  42: fork\n",
      "  43: knife\n",
      "  44: spoon\n",
      "  45: bowl\n",
      "  46: banana\n",
      "  47: apple\n",
      "  48: sandwich\n",
      "  49: orange\n",
      "  50: broccoli\n",
      "  51: carrot\n",
      "  52: hot dog\n",
      "  53: pizza\n",
      "  54: donut\n",
      "  55: cake\n",
      "  56: chair\n",
      "  57: couch\n",
      "  58: potted plant\n",
      "  59: bed\n",
      "  60: dining table\n",
      "  61: toilet\n",
      "  62: tv\n",
      "  63: laptop\n",
      "  64: mouse\n",
      "  65: remote\n",
      "  66: keyboard\n",
      "  67: cell phone\n",
      "  68: microwave\n",
      "  69: oven\n",
      "  70: toaster\n",
      "  71: sink\n",
      "  72: refrigerator\n",
      "  73: book\n",
      "  74: clock\n",
      "  75: vase\n",
      "  76: scissors\n",
      "  77: teddy bear\n",
      "  78: hair drier\n",
      "  79: toothbrush\n",
      "\n",
      "# Download script/URL (optional)\n",
      "download: https://github.com/ultralytics/assets/releases/download/v0.0.0/coco128.zip\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('CVC_challenge_env\\\\Lib\\\\site-packages\\\\ultralytics\\\\cfg\\\\datasets\\\\coco128.yaml', 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "    print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recognision on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\Gebruiker\\OneDrive - Thomas More\\Bureaublad\\CVC_challenge\\CVC_challenge_env\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"c:\\Users\\Gebruiker\\OneDrive - Thomas More\\Bureaublad\\CVC_challenge\\CVC_challenge_env\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 754, in entrypoint\n",
      "    check_dict_alignment(full_args_dict, {a: \"\"})\n",
      "  File \"c:\\Users\\Gebruiker\\OneDrive - Thomas More\\Bureaublad\\CVC_challenge\\CVC_challenge_env\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 436, in check_dict_alignment\n",
      "    raise SyntaxError(string + CLI_HELP_MSG) from e\n",
      "SyntaxError: '\u001b[31m\u001b[1mand\u001b[0m' is not a valid YOLO argument. \n",
      "\n",
      "    Arguments received: ['yolo', 'predict', 'model=yolo11s.pt', \"source='image.jpg'\", 'conf=0.5', 'iou=0.5', '#threshold', '=', '0.5', 'and', 'non-max', 'suppression', '=', '0.5']. Ultralytics 'yolo' commands use the following syntax:\n",
      "\n",
      "        yolo TASK MODE ARGS\n",
      "\n",
      "        Where   TASK (optional) is one of {'segment', 'classify', 'obb', 'pose', 'detect'}\n",
      "                MODE (required) is one of {'predict', 'train', 'export', 'benchmark', 'val', 'track'}\n",
      "                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n",
      "                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n",
      "\n",
      "    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n",
      "        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n",
      "\n",
      "    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n",
      "        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n",
      "\n",
      "    3. Val a pretrained detection model at batch-size 1 and image size 640:\n",
      "        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n",
      "\n",
      "    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n",
      "        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n",
      "    \n",
      "    5. Streamlit real-time webcam inference GUI\n",
      "        yolo streamlit-predict\n",
      "        \n",
      "    6. Run special commands:\n",
      "        yolo help\n",
      "        yolo checks\n",
      "        yolo version\n",
      "        yolo settings\n",
      "        yolo copy-cfg\n",
      "        yolo cfg\n",
      "\n",
      "    Docs: https://docs.ultralytics.com\n",
      "    Community: https://community.ultralytics.com\n",
      "    GitHub: https://github.com/ultralytics/ultralytics\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "!yolo predict model=yolo11s.pt source='image.jpg' conf=0.5 iou=0.5 #threshold = 0.5 and non-max suppression = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.18 üöÄ Python-3.12.0 torch-2.5.0+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "YOLO11s-seg summary (fused): 265 layers, 10,097,776 parameters, 0 gradients, 35.5 GFLOPs\n",
      "\n",
      "image 1/1 c:\\Users\\Gebruiker\\OneDrive - Thomas More\\Bureaublad\\CVC_challenge\\image.jpg: 416x640 3 cars, 269.8ms\n",
      "Speed: 5.2ms preprocess, 269.8ms inference, 15.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Results saved to \u001b[1mc:\\Users\\Gebruiker\\OneDrive - Thomas More\\Bureaublad\\CVC_challenge\\runs\\segment\\predict2\u001b[0m\n",
      "üí° Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "# segmentation\n",
    "# !yolo task=segment mode=predict model=yolo11s-seg.pt source='image.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.18 üöÄ Python-3.12.0 torch-2.5.0+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11s.pt, data=CVC_v1i_yolov11/data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train10, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=c:\\Users\\Gebruiker\\OneDrive - Thomas More\\Bureaublad\\CVC_challenge\\runs\\detect\\train10\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\Gebruiker\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    820182  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "YOLO11s summary: 319 layers, 9,428,566 parameters, 9,428,550 gradients, 21.6 GFLOPs\n",
      "\n",
      "Transferred 493/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\Gebruiker\\OneDrive - Thomas More\\Bureaublad\\CVC_challenge\\CVC_v1i_yolov11\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Gebruiker\\OneDrive - Thomas More\\Bureaublad\\CVC_challenge\\CVC_v1i_yolov11\\valid\\labels.cache\n",
      "Plotting labels to c:\\Users\\Gebruiker\\OneDrive - Thomas More\\Bureaublad\\CVC_challenge\\runs\\detect\\train10\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Gebruiker\\OneDrive - Thomas More\\Bureaublad\\CVC_challenge\\runs\\detect\\train10\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all          3         11          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all          3         11          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all          3         11     0.0143      0.222     0.0181    0.00819\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all          3         11     0.0245     0.0556     0.0326     0.0223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all          3         11       0.58      0.211     0.0472     0.0271\n",
      "\n",
      "5 epochs completed in 0.042 hours.\n",
      "Optimizer stripped from c:\\Users\\Gebruiker\\OneDrive - Thomas More\\Bureaublad\\CVC_challenge\\runs\\detect\\train10\\weights\\last.pt, 19.1MB\n",
      "Optimizer stripped from c:\\Users\\Gebruiker\\OneDrive - Thomas More\\Bureaublad\\CVC_challenge\\runs\\detect\\train10\\weights\\best.pt, 19.1MB\n",
      "\n",
      "Validating c:\\Users\\Gebruiker\\OneDrive - Thomas More\\Bureaublad\\CVC_challenge\\runs\\detect\\train10\\weights\\best.pt...\n",
      "Ultralytics 8.3.18 üöÄ Python-3.12.0 torch-2.5.0+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "YOLO11s summary (fused): 238 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "                   all          3         11      0.583      0.221     0.0469     0.0271\n",
      "                 House          1          2          1          0          0          0\n",
      "                  Tree          3          9      0.166      0.441     0.0939     0.0541\n",
      "Speed: 1.2ms preprocess, 113.9ms inference, 0.0ms loss, 147.1ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Gebruiker\\OneDrive - Thomas More\\Bureaublad\\CVC_challenge\\runs\\detect\\train10\u001b[0m\n",
      "üí° Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/755k [00:00<?, ?B/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 7.20MB/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 7.20MB/s]\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Gebruiker\\OneDrive - Thomas More\\Bureaublad\\CVC_challenge\\CVC_v1i_yolov11\\train\\labels...:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Gebruiker\\OneDrive - Thomas More\\Bureaublad\\CVC_challenge\\CVC_v1i_yolov11\\train\\labels... 22 images, 0 backgrounds, 0 corrupt:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 22/30 [00:00<00:00, 202.74it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Gebruiker\\OneDrive - Thomas More\\Bureaublad\\CVC_challenge\\CVC_v1i_yolov11\\train\\labels... 30 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 254.75it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Gebruiker\\OneDrive - Thomas More\\Bureaublad\\CVC_challenge\\CVC_v1i_yolov11\\valid\\labels...:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Gebruiker\\OneDrive - Thomas More\\Bureaublad\\CVC_challenge\\CVC_v1i_yolov11\\valid\\labels... 3 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 741.52it/s]\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "        1/5         0G      2.434      4.538      1.733        216        640:   0%|          | 0/2 [00:20<?, ?it/s]\n",
      "        1/5         0G      2.434      4.538      1.733        216        640:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:20<00:20, 20.21s/it]\n",
      "        1/5         0G      2.352      4.524      1.704        193        640:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:33<00:20, 20.21s/it]\n",
      "        1/5         0G      2.352      4.524      1.704        193        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:33<00:00, 16.30s/it]\n",
      "        1/5         0G      2.352      4.524      1.704        193        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:33<00:00, 16.89s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.17s/it]\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "        2/5         0G      2.077      3.989      1.607        239        640:   0%|          | 0/2 [00:14<?, ?it/s]\n",
      "        2/5         0G      2.077      3.989      1.607        239        640:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:14<00:14, 14.44s/it]\n",
      "        2/5         0G      1.975      4.005      1.578        159        640:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:26<00:14, 14.44s/it]\n",
      "        2/5         0G      1.975      4.005      1.578        159        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:26<00:00, 13.15s/it]\n",
      "        2/5         0G      1.975      4.005      1.578        159        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:26<00:00, 13.35s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.43it/s]\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "        3/5         0G      1.815       3.44      1.391        237        640:   0%|          | 0/2 [00:12<?, ?it/s]\n",
      "        3/5         0G      1.815       3.44      1.391        237        640:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:12<00:12, 12.74s/it]\n",
      "        3/5         0G      1.697      3.195      1.367        168        640:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:23<00:12, 12.74s/it]\n",
      "        3/5         0G      1.697      3.195      1.367        168        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:23<00:00, 11.77s/it]\n",
      "        3/5         0G      1.697      3.195      1.367        168        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:23<00:00, 11.91s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.45it/s]\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "        4/5         0G      1.628      2.846      1.349        234        640:   0%|          | 0/2 [00:12<?, ?it/s]\n",
      "        4/5         0G      1.628      2.846      1.349        234        640:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:12<00:12, 12.82s/it]\n",
      "        4/5         0G      1.548      2.857      1.323        122        640:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:23<00:12, 12.82s/it]\n",
      "        4/5         0G      1.548      2.857      1.323        122        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:23<00:00, 11.81s/it]\n",
      "        4/5         0G      1.548      2.857      1.323        122        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:23<00:00, 11.96s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.03it/s]\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "        5/5         0G      1.573      2.343      1.276        225        640:   0%|          | 0/2 [00:18<?, ?it/s]\n",
      "        5/5         0G      1.573      2.343      1.276        225        640:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:18<00:18, 18.51s/it]\n",
      "        5/5         0G      1.461      2.385      1.283        124        640:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:32<00:18, 18.51s/it]\n",
      "        5/5         0G      1.461      2.385      1.283        124        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:32<00:00, 15.89s/it]\n",
      "        5/5         0G      1.461      2.385      1.283        124        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:32<00:00, 16.28s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.17it/s]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "!yolo task=detect mode=train model=yolo11s.pt data=CVC_v1i_yolov11/data.yaml epochs=5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OD in game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import win32gui, win32ui, win32con\n",
    "from PIL import Image\n",
    "from time import sleep\n",
    "import cv2 as cv\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowCapture:\n",
    "    w = 0\n",
    "    h = 0\n",
    "    hwnd = None\n",
    "\n",
    "    def __init__(self, window_name):\n",
    "        self.hwnd = win32gui.FindWindow(None, window_name)\n",
    "        if not self.hwnd:\n",
    "            raise Exception('Window not found: {}'.format(window_name))\n",
    "\n",
    "        window_rect = win32gui.GetWindowRect(self.hwnd)\n",
    "        self.w = window_rect[2] - window_rect[0]\n",
    "        self.h = window_rect[3] - window_rect[1]\n",
    "\n",
    "        border_pixels = 8\n",
    "        titlebar_pixels = 30\n",
    "        self.w = self.w - (border_pixels * 2)\n",
    "        self.h = self.h - titlebar_pixels - border_pixels\n",
    "        self.cropped_x = border_pixels\n",
    "        self.cropped_y = titlebar_pixels\n",
    "\n",
    "    def get_screenshot(self):\n",
    "        wDC = win32gui.GetWindowDC(self.hwnd)\n",
    "        dcObj = win32ui.CreateDCFromHandle(wDC)\n",
    "        cDC = dcObj.CreateCompatibleDC()\n",
    "        dataBitMap = win32ui.CreateBitmap()\n",
    "        dataBitMap.CreateCompatibleBitmap(dcObj, self.w, self.h)\n",
    "        cDC.SelectObject(dataBitMap)\n",
    "        cDC.BitBlt((0, 0), (self.w, self.h), dcObj, (self.cropped_x, self.cropped_y), win32con.SRCCOPY)\n",
    "\n",
    "        signedIntsArray = dataBitMap.GetBitmapBits(True)\n",
    "        img = np.fromstring(signedIntsArray, dtype='uint8')\n",
    "        img.shape = (self.h, self.w, 4)\n",
    "\n",
    "        dcObj.DeleteDC()\n",
    "        cDC.DeleteDC()\n",
    "        win32gui.ReleaseDC(self.hwnd, wDC)\n",
    "        win32gui.DeleteObject(dataBitMap.GetHandle())\n",
    "\n",
    "        img = img[...,:3]\n",
    "        img = np.ascontiguousarray(img) \n",
    "            \n",
    "        return img\n",
    "\n",
    "    def generate_image_dataset(self):\n",
    "        if not os.path.exists(\"images\"):\n",
    "            os.mkdir(\"images\")\n",
    "        while(True):\n",
    "            img = self.get_screenshot()\n",
    "            im = Image.fromarray(img[..., [2, 1, 0]])\n",
    "            im.save(f\"./images/img_{len(os.listdir('images'))}.jpeg\")\n",
    "            sleep(1)\n",
    "    \n",
    "    def get_window_size(self):\n",
    "        return (self.w, self.h)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ImageProcessor:\n",
    "    def __init__(self, window_size, model_path):\n",
    "        # Load YOLOv11 model from a given path\n",
    "        self.model = torch.hub.load('ultralytics/yolov11', 'custom', path=model_path)  # YOLOv11 from Ultralytics\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device).eval()  # Put the model in evaluation mode\n",
    "        \n",
    "    def process_image(self, img):\n",
    "        # Preprocess the image for YOLOv11\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        img_tensor = torch.from_numpy(img).float().permute(2, 0, 1) / 255.0\n",
    "        img_tensor = img_tensor.unsqueeze(0).to(self.device)\n",
    "        \n",
    "        # Perform inference\n",
    "        with torch.no_grad():\n",
    "            detections = self.model(img_tensor)\n",
    "        \n",
    "        # Extract bounding boxes, confidence, and class predictions\n",
    "        results = detections.xyxy[0].cpu().numpy()\n",
    "        coordinates = []\n",
    "        for x1, y1, x2, y2, conf, cls in results:\n",
    "            coordinates.append({\n",
    "                'x': int(x1),\n",
    "                'y': int(y1),\n",
    "                'w': int(x2 - x1),\n",
    "                'h': int(y2 - y1),\n",
    "                'class': int(cls),\n",
    "                'confidence': float(conf),\n",
    "                'class_name': self.model.names[int(cls)]\n",
    "            })\n",
    "        return coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_name = \"Forza Horizon 4\"\n",
    "model_path = \"yolo11s.pt\"  # Replace with your YOLOv11 model path\n",
    "\n",
    "wincap = WindowCapture(window_name)\n",
    "improc = ImageProcessor(wincap.get_window_size(), model_path)\n",
    "\n",
    "while True:\n",
    "    ss = wincap.get_screenshot()\n",
    "\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        cv.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "    coordinates = improc.process_image(ss)\n",
    "    \n",
    "    for coordinate in coordinates:\n",
    "        print(coordinate)\n",
    "    print()\n",
    "    \n",
    "    # If you have limited computer resources, consider adding a sleep delay between detections.\n",
    "    # sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Chat gpt code\n",
    "    \n",
    "# import win32gui, win32ui, win32con, win32api\n",
    "# from PIL import Image\n",
    "\n",
    "# def capture_screen(region=None):\n",
    "#     hwin = win32gui.GetDesktopWindow()\n",
    "#     if region:\n",
    "#         left, top, right, bot = region\n",
    "#         width = right - left\n",
    "#         height = bot - top\n",
    "#     else:\n",
    "#         width = win32api.GetSystemMetrics(win32con.SM_CXVIRTUALSCREEN)\n",
    "#         height = win32api.GetSystemMetrics(win32con.SM_CYVIRTUALSCREEN)\n",
    "#         left = win32api.GetSystemMetrics(win32con.SM_XVIRTUALSCREEN)\n",
    "#         top = win32api.GetSystemMetrics(win32con.SM_YVIRTUALSCREEN)\n",
    "\n",
    "#     hwindc = win32gui.GetWindowDC(hwin)\n",
    "#     srcdc = win32ui.CreateDCFromHandle(hwindc)\n",
    "#     memdc = srcdc.CreateCompatibleDC()\n",
    "#     bmp = win32ui.CreateBitmap()\n",
    "#     bmp.CreateCompatibleBitmap(srcdc, width, height)\n",
    "#     memdc.SelectObject(bmp)\n",
    "#     memdc.BitBlt((0, 0), (width, height), srcdc, (left, top), win32con.SRCCOPY)\n",
    "\n",
    "#     bmpinfo = bmp.GetInfo()\n",
    "#     bmpstr = bmp.GetBitmapBits(True)\n",
    "#     img = Image.frombuffer('RGB', (bmpinfo['bmWidth'], bmpinfo['bmHeight']), bmpstr, 'raw', 'BGRX', 0, 1)\n",
    "\n",
    "#     win32gui.DeleteObject(bmp.GetHandle())\n",
    "#     memdc.DeleteDC()\n",
    "#     srcdc.DeleteDC()\n",
    "#     win32gui.ReleaseDC(hwin, hwindc)\n",
    "\n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# # Load your YOLO model\n",
    "# model = YOLO('yolo11s.pt')  # or any other YOLO model you use\n",
    "\n",
    "# def detect_objects(frame):\n",
    "#     # Convert PIL image to OpenCV format\n",
    "#     frame = np.array(frame)\n",
    "#     frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#     # Perform YOLO prediction\n",
    "#     results = model(frame)\n",
    "\n",
    "#     # Visualize or process results\n",
    "#     annotated_frame = results[0].plot()  # YOLO will return an annotated frame\n",
    "#     return annotated_frame\n",
    "\n",
    "# # Capture a screen region (game window)\n",
    "# region = (0, 0, 800, 600)  # Adjust to your game window size\n",
    "# while True:\n",
    "#     screen = capture_screen(region)\n",
    "#     detected_frame = detect_objects(screen)\n",
    "\n",
    "#     # Display the detection\n",
    "#     cv2.imshow(\"Game Object Detection\", detected_frame)\n",
    "\n",
    "#     # Exit on 'q' key\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detect_objects(frame):\n",
    "#     # Resize frame before detection for faster inference\n",
    "#     frame_resized = cv2.resize(frame, (640, 640))\n",
    "\n",
    "#     # Perform YOLO prediction\n",
    "#     results = model(frame_resized)\n",
    "\n",
    "#     # Return results (annotated frame)\n",
    "#     return results[0].plot()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVC_challenge_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
